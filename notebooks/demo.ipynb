{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from drise.core.explainer import DRISE\n",
    "from drise.core.utils import (\n",
    "    get_data_path,\n",
    "    load_image,\n",
    "    rescale_boxes,\n",
    "    resize_image_for_detector,\n",
    "    upscale_saliency_map,\n",
    ")\n",
    "from drise.core.visualization import COCO_CLASSES_91, DRISEVisualizer\n",
    "from drise.core.wrappers.faster_rcnn import TorchvisionFasterRCNNWrapper\n",
    "from drise.core.wrappers.yolo import YOLOWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Demo Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_faster_rcnn(\n",
    "    image_path: str,\n",
    "    num_masks: int = 5000,\n",
    "    mask_res: tuple = (16, 16),\n",
    "    mask_prob: float = 0.5,\n",
    "    save_path: str = get_data_path() / \"rcnn_drise_results.png\",\n",
    "):\n",
    "    \"\"\"\n",
    "    End-to-end D-RISE demo with torchvision Faster R-CNN.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image.\n",
    "        num_masks: Number of random masks (paper: 5000).\n",
    "        mask_res: Low-resolution mask grid size.\n",
    "        mask_prob: Pixel preservation probability (paper: 0.5).\n",
    "        batch_size: Masked images per forward pass. Higher = faster.\n",
    "            Reduce if running out of GPU memory.\n",
    "        save_path: Output visualization path.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"D-RISE Demo — Faster R-CNN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\n[1/5] Loading image...\")\n",
    "    image_original = load_image(image_path)\n",
    "    image_resized = resize_image_for_detector(\n",
    "        image_original, detector_type=\"fasterrcnn\"\n",
    "    )\n",
    "    _, orig_H, orig_W = image_original.shape\n",
    "    _, work_H, work_W = image_resized.shape\n",
    "    print(f\"      Original:  {orig_H}x{orig_W}\")\n",
    "    print(f\"      Working:   {work_H}x{work_W}\")\n",
    "\n",
    "    cell_h = int(np.ceil(work_H / mask_res[0]))\n",
    "    cell_w = int(np.ceil(work_W / mask_res[1]))\n",
    "    print(f\"      Mask grid: {mask_res} → cell size: {cell_h}x{cell_w} px\")\n",
    "\n",
    "    print(\"\\n[2/5] Loading Faster R-CNN...\")\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=True\n",
    "    )\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"      Device: {device}\")\n",
    "\n",
    "    display_detector = TorchvisionFasterRCNNWrapper(\n",
    "        model, device=device, score_threshold=0.5\n",
    "    )\n",
    "    explain_detector = TorchvisionFasterRCNNWrapper(\n",
    "        model, device=device, score_threshold=0.01\n",
    "    )\n",
    "\n",
    "    print(\"\\n[3/5] Running detector...\")\n",
    "    detections = display_detector.detect(image_resized)\n",
    "    print(f\"      Found {len(detections)} detections:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        name = COCO_CLASSES_91[det.label]\n",
    "        print(f\"      [{i}] {name} (score={det.score:.3f})\")\n",
    "\n",
    "    if len(detections) == 0:\n",
    "        print(\"      No detections found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[4/5] Running D-RISE...\")\n",
    "    print(f\"      N={num_masks}, res={mask_res}, p={mask_prob}\")\n",
    "\n",
    "    drise = DRISE(\n",
    "        detector=explain_detector,\n",
    "        num_masks=num_masks,\n",
    "        mask_res=mask_res,\n",
    "        mask_prob=mask_prob,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    target_dets = [\n",
    "        {\"box\": det.box, \"label\": det.label} for det in detections\n",
    "    ]\n",
    "\n",
    "    saliency_maps = drise.explain(\n",
    "        image=image_resized,\n",
    "        target_detections=target_dets,\n",
    "        num_classes=91,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[5/5] Upscaling and saving to {save_path}...\")\n",
    "\n",
    "    saliency_maps_original = [\n",
    "        upscale_saliency_map(smap, orig_H, orig_W)\n",
    "        for smap in saliency_maps\n",
    "    ]\n",
    "\n",
    "    target_dets_original = rescale_boxes(\n",
    "        target_dets, work_H, work_W, orig_H, orig_W\n",
    "    )\n",
    "\n",
    "    DRISEVisualizer.visualize_explanations(\n",
    "        image=image_original,\n",
    "        target_detections=target_dets_original,\n",
    "        saliency_maps=saliency_maps_original,\n",
    "        save_path=save_path,\n",
    "    )\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Demo YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_yolo(\n",
    "    image_path: str,\n",
    "    num_masks: int = 5000,\n",
    "    mask_res: tuple = (16, 16),\n",
    "    mask_prob: float = 0.5,\n",
    "    save_path: str = get_data_path() / \"yolo_drise_results.png\",\n",
    "):\n",
    "    \"\"\"\n",
    "    End-to-end D-RISE demo with ultralytics YOLO.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image.\n",
    "        num_masks: Number of random masks (paper: 5000).\n",
    "        mask_res: Low-resolution mask grid size.\n",
    "        mask_prob: Pixel preservation probability (paper: 0.5).\n",
    "        batch_size: Masked images per forward pass.\n",
    "        save_path: Output visualization path.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"D-RISE Demo — YOLOv8\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\n[1/5] Loading image...\")\n",
    "    image_original = load_image(image_path)\n",
    "    image_resized = resize_image_for_detector(\n",
    "        image_original, detector_type=\"yolo\"\n",
    "    )\n",
    "    _, orig_H, orig_W = image_original.shape\n",
    "    _, work_H, work_W = image_resized.shape\n",
    "    print(f\"      Original:  {orig_H}x{orig_W}\")\n",
    "    print(f\"      Working:   {work_H}x{work_W}\")\n",
    "\n",
    "    cell_h = int(np.ceil(work_H / mask_res[0]))\n",
    "    cell_w = int(np.ceil(work_W / mask_res[1]))\n",
    "    print(f\"      Mask grid: {mask_res} → cell size: {cell_h}x{cell_w} px\")\n",
    "\n",
    "    print(\"\\n[2/5] Loading YOLOv8...\")\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"      Device: {device}\")\n",
    "\n",
    "    display_detector = YOLOWrapper(\n",
    "        model, device=device, score_threshold=0.5, num_classes=80\n",
    "    )\n",
    "    explain_detector = YOLOWrapper(\n",
    "        model, device=device, score_threshold=0.01, num_classes=80\n",
    "    )\n",
    "\n",
    "    print(\"\\n[3/5] Running detector...\")\n",
    "    detections = display_detector.detect(image_resized)\n",
    "    print(f\"      Found {len(detections)} detections:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        print(f\"      [{i}] class={det.label} (score={det.score:.3f})\")\n",
    "\n",
    "    if len(detections) == 0:\n",
    "        print(\"      No detections found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[4/5] Running D-RISE...\")\n",
    "    print(f\"      N={num_masks}, res={mask_res}, p={mask_prob}\")\n",
    "\n",
    "    drise = DRISE(\n",
    "        detector=explain_detector,\n",
    "        num_masks=num_masks,\n",
    "        mask_res=mask_res,\n",
    "        mask_prob=mask_prob,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    target_dets = [\n",
    "        {\"box\": det.box, \"label\": det.label} for det in detections\n",
    "    ]\n",
    "\n",
    "    saliency_maps = drise.explain(\n",
    "        image=image_resized,\n",
    "        target_detections=target_dets,\n",
    "        num_classes=80,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[5/5] Upscaling and saving to {save_path}...\")\n",
    "\n",
    "    saliency_maps_original = [\n",
    "        upscale_saliency_map(smap, orig_H, orig_W)\n",
    "        for smap in saliency_maps\n",
    "    ]\n",
    "\n",
    "    target_dets_original = rescale_boxes(\n",
    "        target_dets, work_H, work_W, orig_H, orig_W\n",
    "    )\n",
    "\n",
    "    DRISEVisualizer.visualize_explanations(\n",
    "        class_names=model.names,\n",
    "        image=image_original,\n",
    "        target_detections=target_dets_original,\n",
    "        saliency_maps=saliency_maps_original,\n",
    "        save_path=save_path,\n",
    "    )\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = get_data_path() / \"cat.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_faster_rcnn(IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_yolo(IMG_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drise-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
